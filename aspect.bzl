load("//:plugin.bzl", "ProtoPluginInfo")

proto_compile_aspect_attrs = {
    "verbose_string": attr.string(
        doc = "Increase verbose level for more debugging",
        values = ["0", "1", "2", "3", "4"],
    ),
    # "plugin_options": attr.string_list(
    #     doc = "List of additional 'global' options to add (applies to all plugins)",
    # ),
    # "outputs": attr.output_list(
    #     doc = "Escape mechanism to explicitly declare files that will be generated",
    # ),
    # "transitive": attr.bool(
    #     doc = "Emit transitive artifacts",
    # ),
    # "transitivity": attr.string_dict(
    #     doc = "Transitive rules.  When the 'transitive' property is enabled, this string_dict can be used to exclude protos from the compilation list",
    # ),
}


ProtoLibraryAspectNodeInfo = provider(
    fields = {
        "target": "the target we visited",
        "ctx": "the aspect ctx object", 
        "ctx_label": "the ctx.label object", 
        "rule": "the ctx.rule object", 
        "actions": "the ctx.actions function",
        "outputs": "the files generated by this aspect"
    },
)

def _describe(name, obj, exclude):
    """Print the properties of the given struct obj
    Args:
      name: the name of the struct we are introspecting.
      obj: the struct to introspect
      exclude: a list of names *not* to print (function names)
    """
    for k in dir(obj):
        if hasattr(obj, k) and k not in exclude:
            v = getattr(obj, k)
            t = type(v)
            print("%s.%s<%r> = %s" % (name, k, t, v))


def get_bool_attr(attr, name):
    value = getattr(attr, name, "False")
    return value == "True"

def get_int_attr(attr, name):
    value = getattr(attr, name)
    if value == "None":
        return 0
    return int(value)

def get_string_list_attr(attr, name):
    value = getattr(attr, name, "")
    if value == "":
        return []
    return value.split(";")

def proto_compile_aspect_impl(target, ctx):
    # node - the proto_library rule node we're visiting
    node = ctx.rule

    # Confirm the node is a proto_library otherwise return no providers.
    if node.kind != "proto_library":
        return []

    # print("ctx: %r\n\n\n" % ctx)
    # _describe("ctx", ctx, [
    #     "action", 
    #     "check_placeholders", 
    #     "coverage_instrumented", 
    #     "created_actions",
    #     "empty_action",
    #     "expand",
    #     "expand_location",
    #     "expand_make_variables",
    #     "experimental_new_directory",
    #     "file_action",
    #     "new_file",
    #     "outputs",
    #     "resolve_command",
    #     "runfiles",
    #     "split_attr",
    #     "template_action",
    #     "tokenize",
    # ])
    # print("\n\n\n")
    # _describe("ctx.configuration", ctx.configuration, [])
    # _describe("ctx.host_configuration", ctx.host_configuration, [])
    # _describe("ctx.toolchains", ctx.toolchains, [])
    # # This is interesting
    # # _describe("ctx.fragments", ctx.fragments, ["android"])
    # _describe("ctx.actions", ctx.actions, [
    #     "args",
    #     "declare_directory",
    #     "declare_file",
    #     "do_nothing",
    #     "expand_template",
    #     "run",
    #     "run_shell",
    #     "write",
    # ])

    _describe("ctx.attr", ctx.attr, [
        "to_json",
        "to_proto",
    ])

    verbose = get_int_attr(ctx.attr, "verbose_string")

    print("you requested verbose level %d" % verbose)

    # <list<PluginInfo>> A list of PluginInfo 
    plugins = [plugin[ProtoPluginInfo] for plugin in ctx.attr._plugins]

    # <list<ProtoInfo>> A list of ProtoInfo 
    # deps = [dep.proto for dep in node.attr.deps]
    deps = [dep.proto for dep in node.attr.deps]
    print("deps: %r" % deps)
    for d in deps:
        _describe("ProtoInfo", d, [])
        
    # <Generated File> the protoc tool
    protoc = node.executable._proto_compiler

    # list<File> the set of direct proto files to compile 
    protos = node.files.srcs

    # list<Generated File> The files we expect to generate
    outputs = []

    # <File> for the output descriptor.  Often used as the sibling in
    # 'declare_file' actions.
    # print(dir(node))
    # print(node.files)
    descriptor = target.files.to_list()[0]
    # descriptor = ctx.actions.declare_file(ctx.label.name+"_descriptor.bin")
    # outputs.append(descriptor)

    # <string> The directory where that generated descriptor is.
    outdir = descriptor.dirname

    # <dict<string,File>> A mapping from plugin name to the plugin tool. Used to
    # generate the --plugin=protoc-gen-KEY=VALUE args
    plugin_tools = {}

    # <list<File>> The list of srcjars that we're generating (like
    # 'foo.srcjar').
    srcjars = []
    
    # Additional data files from plugin.data needed by plugin tools that are not
    # single binaries. 
    data = []

    ###
    ### Part 2: gather plugin.out artifacts
    ###

    # Some protoc plugins generate a set of output files (like python) while
    # others generate a single 'archive' file that contains the individual
    # outputs (like java).  This first loop is for the latter type.  In this
    # scenario, the PluginInfo.out attribute will exist; the predicted file
    # output location is relative to the package root, marked by the descriptor
    # file. Jar outputs are gathered as a special case as we need to
    # post-process them to have a 'srcjar' extension (java_library rules don't
    # accept source jars with a 'jar' extension)
    for plugin in plugins:
        if plugin.executable:    
            plugin_tools[plugin.name] = plugin.executable
        data += plugin.data + get_plugin_runfiles(plugin.tool)

        filename = _get_plugin_out(ctx, plugin)
        if not filename:
            continue
        out = ctx.actions.declare_file(filename, sibling = descriptor)
        outputs.append(out)
        plugin_outfiles[plugin.name] = out
        if out.path.endswith(".jar"):
            srcjar = _copy_jar_to_srcjar(ctx, out)
            srcjars.append(srcjar)


    ###
    ### Part 3c: collect generated artifacts for all in the target list of protos to compile
    ###
    for proto in protos:
        for plugin in plugins:
            outputs = _get_plugin_outputs(ctx, descriptor, outputs, proto, plugin)

    print("target.files: %r" % target.files)
    descriptor_sets = depset(
        direct = target.files.to_list(),
        transitive = [d.transitive_descriptor_sets for d in deps]
    )

    import_files = depset(
        direct = node.files.srcs,
        # transitive = [d.transitive_proto_path for d in deps]
        transitive = [d.transitive_imports for d in deps]
        # transitive = [d.proto_source_root for d in deps]
    )

    # By default we have a single 'proto_path' argument at the 'staging area'
    # root.
    # list<string> argument list to construct
    args = []

    # args = ["--descriptor_set_out=%s" % descriptor.path]

    pathsep = ctx.configuration.host_path_separator

    args.append("--descriptor_set_in=%s" % pathsep.join(
        [f.path for f in descriptor_sets]    
    ))

    # <dict<string,<File> A mapping from PluginInfo.name to File.  In the case
    # of plugins that specify a single output 'archive' (like java), we gather
    # them in this dict.  It is used to generate args like
    # '--java_out=libjava.jar'.  
    plugin_outfiles = {}

    plugin_options = get_string_list_attr(ctx.attr, "plugin_options_string")

    for plugin in plugins:
        args += [get_plugin_out_arg(ctx, outdir, plugin, plugin_options, plugin_outfiles)]        

    args += ["--plugin=protoc-gen-%s=%s" % (k, v.path) for k, v in plugin_tools.items()]

    args += [_proto_path(f) for f in protos]

    mnemonic = "ProtoCompile"

    command = " ".join([protoc.path] + args)

    if verbose > 0:
        print("%s: %s" % (mnemonic, command))
    if verbose > 1:
        command += " && echo '\n##### SANDBOX AFTER RUNNING PROTOC' && find . -type f "
    if verbose > 2:
        command = "echo '\n##### SANDBOX BEFORE RUNNING PROTOC' && find . -type l && " + command
    if verbose > 3:
        command = "env && " + command
        for f in outputs:
            print("expected output: %q", f.path)    

    ctx.actions.run_shell(
        mnemonic = mnemonic,
        command = command,
        inputs = [protoc] + plugin_tools.values() + data + import_files.to_list() + descriptor_sets.to_list(),
        outputs = outputs,
    )

    return [ProtoLibraryAspectNodeInfo(
        outputs = outputs,
    )]

# proto_compile_aspect = aspect(
#     implementation = _proto_compile_aspect_impl,
#     attr_aspects = ["deps"],
#     attrs = {
#         "_plugins": attr.label_list(
#             doc = "List of protoc plugins to apply",
#             providers = [ProtoPluginInfo],
#             mandatory = True,
#         ),
#     },
# )

# Shamelessly taken from https://github.com/bazelbuild/rules_go
def _proto_path(proto):
    """
    The proto path is not really a file path
    It's the path to the proto that was seen when the descriptor file was generated.
    """
    path = proto.path
    root = proto.root.path
    ws = proto.owner.workspace_root
    if path.startswith(root):
        path = path[len(root):]
    if path.startswith("/"):
        path = path[1:]
    if path.startswith(ws):
        path = path[len(ws):]
    if path.startswith("/"):
        path = path[1:]
    return path


ProtoCompileInfo = provider(fields = {
    "label": "label object",
    "plugins": "ProtoPluginInfo object",
    "descriptor": "descriptor set file",
    "outputs": "generated protoc outputs",
    "files": "final generated files",
    "protos": "generated protos (copies)",
    "args": "proto arguments",
    "tools": "proto tools",
    "verbose": "verbose level",
})

rust_keywords = {
    "as": True,
    "break": True,
    "const": True,
    "continue": True,
    "crate": True,
    "else": True,
    "enum": True,
    "extern": True,
    "false": True,
    "fn": True,
    "for": True,
    "if": True,
    "impl": True,
    "let": True,
    "loop": True,
    "match": True,
    "mod": True,
    "move": True,
    "mut": True,
    "pub": True,
    "ref": True,
    "return": True,
    "self": True,
    "Self": True,
    "static": True,
    "struct": True,
    "super": True,
    "trait": True,
    "true": True,
    "type": True,
    "unsafe": True,
    "use": True,
    "where": True,
    "while": True,
}

objc_upper_segments = {
    "url": "URL",
    "http": "HTTP",
    "https": "HTTPS",
}

def _capitalize(s):
  """Capitalize a string - only first letter
  Args:
    s (string): The input string to be capitalized.
  Returns:
    (string): The capitalized string.
  """
  return s[0:1].upper() + s[1:]


def _pascal_objc(s):
    """Convert pascal_case -> PascalCase

    Objective C uses pascal case, but there are e exceptions that it uppercases
    the entire segment: url, http, and https.

    https://github.com/protocolbuffers/protobuf/blob/54176b26a9be6c9903b375596b778f51f5947921/src/google/protobuf/compiler/objectivec/objectivec_helpers.cc#L91

    Args: 
      s (string): The input string to be capitalized. 
    Returns: (string): The capitalized string.
    """
    segments = []
    for segment in s.split("_"):
        repl = objc_upper_segments.get(segment)
        if repl:
            segment = repl
        else:
            segment = _capitalize(segment)
        segments.append(segment)
    return "".join(segments)


def _pascal_case(s):
    """Convert pascal_case -> PascalCase
    Args:
        s (string): The input string to be capitalized.
    Returns:
        (string): The capitalized string.
    """
    return "".join([_capitalize(part) for part in s.split("_")])


def _rust_keyword(s):
    """Check if arg is a rust keyword and append '_pb' if true.
    Args:
        s (string): The input string to be capitalized.
    Returns:
        (string): The appended string.
    """
    return s + "_pb" if rust_keywords.get(s) else s


def _get_output_sibling_file(pattern, proto, descriptor):
    """Get the correct place to output to.

    The ctx.actions.declare_file has a 'sibling = <File>' feature that allows
    one to declare files in the same directory as the sibling.

    This function checks for the prefix special token '{package}' and, if true,
    uses the descriptor as the sibling (which declares the output file will be
    in the root of the generated tree).

    Args:
      pattern: the input filename pattern <string>
      proto: the .proto <Generated File> (in the staging area)
      descriptor: the descriptor <File> that marks the staging root.
    
    Returns:
      the <File> to be used as the correct sibling.
    """

    if pattern.startswith("{package}/"):
        return descriptor
    return proto


def _get_plugin_out(label_name, plugin):
    if not plugin.out:
        return None
    filename = plugin.out
    filename = filename.replace("{name}", label_name)    
    return filename


def _get_output_filename(src, plugin, pattern):
    """Build the predicted filename for file generated by the given plugin.  

    A 'proto_plugin' rule allows one to define the predicted outputs.  For
    flexibility, we allow special tokens in the output filename that get
    replaced here. The overall pattern is '{token}' mimicking the python
    'format' feature.  

    Additionally, there are '|' characters like '{basename|pascal}' that can be
    read as 'take the basename and pipe that through the pascal function'.

    Args: 
      src: the .proto <File> 
      plugin: the <PluginInfo> object.
      pattern: the input pattern string

    Returns: 
      the replaced string
    """

    # If output to srcjar, don't emit a per-proto output file.
    if plugin.out:
        return None
    # Slice off this prefix if it exists, we don't use it here.
    if pattern.startswith("{package}/"):
        pattern = pattern[len("{package}/"):]
    basename = src.basename
    if basename.endswith(".proto"):
        basename = basename[:-6]
    elif basename.endswith(".protodevel"):
        basename = basename[:-11]

    filename = basename
   
    if pattern.find("{basename}") != -1:
        filename = pattern.replace("{basename}", basename)
    elif pattern.find("{basename|pascal}") != -1:
        filename = pattern.replace("{basename|pascal}", _pascal_case(basename))
    elif pattern.find("{basename|pascal|objc}") != -1:
        filename = pattern.replace("{basename|pascal|objc}", _pascal_objc(basename))
    elif pattern.find("{basename|rust_keyword}") != -1:
        filename = pattern.replace("{basename|rust_keyword}", _rust_keyword(basename))
    else:
        filename = basename + pattern

    return filename


def _get_proto_filename(src):
    """Assemble the filename for a proto

    Args:
      src: the .proto <File>

    Returns:
      <string> of the filename.
    """
    parts = src.short_path.split("/")
    if len(parts) > 1 and parts[0] == "..":
        return "/".join(parts[2:])
    return src.short_path


def _copy_jar_to_srcjar(ctx, jar):
    """Copy .jar to .srcjar

    Args:
      ctx: the <ctx> object
      jar: the <Generated File> of a jar containing source files.
    
    Returns:
      <Generated File> for the renamed file
    """
    srcjar = ctx.actions.declare_file("%s/%s.srcjar" % (ctx.label.name, ctx.label.name))
    ctx.actions.run_shell(
        mnemonic = "CopySrcjar",
        inputs = [jar],
        outputs = [srcjar],
        command = "mv %s %s" % (jar.path, srcjar.path),
    )
    return srcjar


def _get_plugin_option(label_name, option):
    """Build a plugin option, doing plugin option template replacements if present

    Args:
      label_name: the ctx.label.name
      option: string from the <PluginInfo>
    
    Returns:
      <string> for the --plugin_out= arg
    """
    # TODO: use .format here and pass in a substitutions struct!
    return option.replace("{name}", label_name)


def _get_plugin_options(label_name, options):
    """Build a plugin option list

    Args:
      label_name: the ctx.label.name
      options: list<string> options from the <PluginInfo>
    
    Returns:
      <string> for the --plugin_out= arg
    """
    return [_get_plugin_option(label_name, option) for option in options]


def get_plugin_out_arg(ctx, outdir, plugin, plugin_options, plugin_outfiles):
    """Build the --java_out argument

    Args:
      ctx: the <ctx> object
      output: the package output directory <string>
      plugin: the <PluginInfo> object.
      plugin_outfiles: The <dict<string,<File>>.  For example, {closure: "library.js"}

    Returns
      <string> for the protoc arg list.
    """
    label_name = ctx.label.name
    arg = ctx.bin_dir.path

    if plugin.outdir:
        arg = plugin.outdir.replace("{name}", outdir)
    elif plugin.out:
        outfile = plugin_outfiles[plugin.name]
        #arg = "%s" % (outdir)
        #arg = "%s/%s" % (outdir, outfile.short_path)
        arg = outfile.path

    # Collate a list of options from the plugin itself PLUS options from the
    # global plugin_options list (if they exist)
    options = getattr(plugin, "options", []) + plugin_options
    if options:
        arg = "%s:%s" % (",".join(_get_plugin_options(label_name, options)), arg) 
    return "--%s_out=%s" % (plugin.name, arg)  


def _apply_plugin_transitivity_rules(ctx, targets, plugin):
    """Process the proto target list according to plugin transitivity rules
    
    Args:
      ctx: the <ctx> object
      targets: the dict<string,File> of .proto files that we intend to compile. 
      plugin: the <PluginInfo> object.

    Returns:
      <list<File>> the possibly filtered list of .proto <File>s
    """

    # Iterate transitivity rules like '{ "google/protobuf": "exclude" }'. The
    # only rule type implemented is "exclude", which checks if the pathname or
    # dirname ends with the given pattern.  If so, remove that item in the
    # targets list.
    #
    # Why does this feature exist?  Well, library rules like C# require all the
    # proto files to be present during the compilation (collected via transitive
    # sources).  However, since the well-known types are already present in the
    # library dependencies, we don't actually want to compile well-known types
    # (but do want to compile everything else).
    #
    transitivity = plugin.transitivity + ctx.attr.transitivity

    for pattern, rule in transitivity.items():
        if rule == "exclude":
            for key, target in targets.items():
                if ctx.attr.verbose > 2:
                    print("Checking '%s' endswith '%s'" % (target.short_path, pattern))
                if target.dirname.endswith(pattern) or target.path.endswith(pattern):
                    targets.pop(key)
                    if ctx.attr.verbose > 2:
                        print("Removing '%s' from the list of files to compile as plugin '%s' excluded it" % (target.short_path, plugin.name))
                else:
                    if ctx.attr.verbose > 2:
                        print("Keeping '%s' (not excluded)" % (target.short_path))
        elif rule == "include":
            for key, target in targets.items():
                if target.dirname.endswith(pattern) or target.path.endswith(pattern):
                    if ctx.attr.verbose > 2:
                        print("Keeping '%s' (explicitly included)" % (target.short_path))
                else:
                    targets.pop(key)
                    if ctx.attr.verbose > 2:
                        print("Removing '%s' from the list of files to compile as plugin '%s' did not include it" % (target.short_path, plugin.name))
        else:
            fail("Unknown transitivity rule '%s'" % rule)
    return targets


def _get_plugin_outputs(ctx, descriptor, outputs, proto, plugin):
    """Get the predicted generated outputs for a given plugin
    
    Args:
      ctx: the <ctx> object
      descriptor: the descriptor <Generated File>
      outputs: the list of outputs. 
      proto: the source .proto <Source File>
      plugin: the <PluginInfo> object.

    Returns:
      <list<Generated File>> the augmented list of files that will be generated
    """
    for output in plugin.outputs:
        filename = _get_output_filename(proto, plugin, output)
        if not filename:
            continue
        # sibling = _get_output_sibling_file(output, proto, descriptor)
        sibling = proto
        print("FILENAME: %s" % filename)
        # output = ctx.actions.declare_file(filename, sibling = sibling)
        output = ctx.actions.declare_file(filename)
        # output = ctx.new_file(filename, root = descriptor)
        
        print("Using sibling file '%s' for '%s' => '%s'" % (sibling.path, filename, output.path))
        outputs.append(output)
    return outputs



def get_plugin_runfiles(tool):
    """Gather runfiles for a plugin.
    """
    files = []
    if not tool:
        return files

    info = tool[DefaultInfo]    
    if not info:
        return files

    if info.files:
        files += info.files.to_list()

    if info.default_runfiles:
        runfiles = info.default_runfiles
        if runfiles.files:
            files += runfiles.files.to_list()

    if info.data_runfiles:
        runfiles = info.data_runfiles
        if runfiles.files:
            files += runfiles.files.to_list()

    return files

